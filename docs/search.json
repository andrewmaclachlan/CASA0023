[
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "\n1  Getting started with remote sensing\n",
    "section": "",
    "text": "To start with we are going to send some time exploring remotely sensed data ready for future analysis. We will first look at Sentinel and then move to Landsat data, which we have seen before in CASA0005.\nYou need to select a city of you choice and then using the image and explanation below…i will use Cape Town, South Africa for the rest of the practical."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Remotely Sensing Cities and Environments",
    "section": "",
    "text": "Andy MacLachlan1\nLast updated: 2022-04-25"
  },
  {
    "objectID": "index.html#acknowledgement",
    "href": "index.html#acknowledgement",
    "title": "CASA0023 Remotely Sensing Cities and Environments",
    "section": "Acknowledgement",
    "text": "Acknowledgement\nThanks to the following academics who inspired the creating of the module and various concepts within it:\n\nDr Ellie Biggs\nDr Gareth Roberts\nDr Bryan Boruff\nProfessor Ted Milton\nDr Laurie Chisholm\n\nThanks again to the following people who have either contributed directly or provided code in repositories that have helped me style this book:\n\n\nR Studio\n\nSTAT 545\nrstudio4edu\nHadley Wickham\nAlison Presmanes Hill\nDesirée De Leon\nYihui Xie\nJulia Silge\nJenny Bryan\nOthers\n\nRobin Lovelace\nTwitter for R programmers\nMatt Ng\nStatQuest with Josh Starmer\nGarrick Aden‑Buie\n\n\n\nThe R package and analysis artwork used within this book has been produced by allison_horst, whilst artwork used in information boxes has been produced by Desirée De Leon. You can find Allison’s images on the stats illustration GitHub repository and Desirée’s on the rstudio4edu GitHub repository.\nI’ve certainly learnt a lot from their open code repositories!"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "CASA0023 Remotely Sensing Cities and Environments",
    "section": "Welcome",
    "text": "Welcome\nHello  and welcome to the Term 2 module Remotely Sensing Cities and Environments.\nSimilarly, to my Term 1 MSc module, CASA0005, this website holds all the practical instructions for the module. CASA0005 Geographic Information Systems and Science is a pre-requisite of the module so concepts taught there will mainly be assumed here."
  },
  {
    "objectID": "intro.html#learning-outcomes",
    "href": "intro.html#learning-outcomes",
    "title": "\n1  Getting started with remote sensing\n",
    "section": "\n1.1 Learning outcomes",
    "text": "1.1 Learning outcomes\nBy the end of this practical you should be able to:\n\nSource, load and articulate the differences between Landsat and Sentinel data\nUndertake basic raster image statistics and processing\nEvaluate the (dis)advantages of each type of software you have used\nPull out and statistically compare spectral signatures\n\n\n1.1.1 Sentinel download\n\nGo to the Copernicus Open Access Hub\n\nYou will need to make a free account\n\nDraw around the study area\nSelect image filter criteria\nSelect search icon\nDownload the S2MSI2A data\n\n\n\n\n\n\n\n\n\n\n\nWithin this image we have:\n\nAllows you to either move around the global or draw a study area\nAn example of a study area\nHow to sort the image results\nSentinel mission selection :\n\n\nSentinel product types refer to the amount of processing that has been undertaken on the multi-spectral imagery. S2MSI2A = Bottom of Atmosphere (BOA) or otherwise known as surface reflectance. Consult the product specification for more details.\n\nYou can also use the Sentinel 2 toolbox to replicate the conversation from TOA to BOA\n\nThe platform refers to either sentinel 2A or 2B. Theses are the same sensors but they operate at 180 degrees from each other reducing the revisit time from 10 to 5 days. 2A was launched first in 2015 followed by 2B in 2017.\nCloud cover e.g. [0 TO 5]\n\n\n1.1.1.1 Open\nOnce downloaded and unzipped you’ll be presented with a load of folders! Here we are interested in the 10m bands…which are:\n\n\n\n\n\n\n\n\nYou’ll find then in the GRANULE > sensor number > IMG_DATA > R10.\nNext open them up in QGIS for some exploration, if there is a TCI image this is a True Colour Image of B02 (Blue), B03 (Green), and B04 (Red) Bands - open this first, it’s just a single raster layer. See the Sentinel user guide definitions for any other acronyms you might need.\n\n\n\n\n\n\n\n\nUsing the Identify tool we can create a spectral signature by changing the view option to graph (look under the graph in the image above).\nHowever the TCI values are coded between 0 and 255 which will limit what we can do with it. As the the radiometric resolution of Sentinel-2 is 12-bit, meaning brightness levels from 0 - 4095 it’s not clear how this product has been made.\nSo we can make our own raster stack using the BOA bands, if you recall we did this in CASA0005 in R.\nBut in QGIS it’s easier to visualise the output\nFind the merge tool from the Raster miscellaneous tool box and select the following:\n\n\n\n\n\n\n\n\nNote:\n\nThe input layers are the four 10m bands that I loaded into QGIS\nThe tick box selected meaning each raster file will be it’s own layer\nThe file being saved into a .tiff as opposed to memory\n\nOnce merged we can created a true colour composite using the BOA data…to do so:\n\nRight click on the merged layer in the attribute table\nSymbology > Render type > select multiband color\n\nIn remote sensing the Red, Green, Blue display options are often called colour guns that are used to display images on the screen. For a true colour composite B1=Blue, B2=Green, B3=Red.\nTry changing the contrast enhancement and see what happens, then consult GIS stack exchange to understand what is happening..\nOf course we have only used the 10m bands so far…there are two options that we can take to use the full range of spectral data:\n\nDownscale the other bands to 10m forming a super-resolution\nUpscale the 10m to 20m\n\nDown scaling is quite an intensive process and beyond the scope of this practical. However, it can be achieved using Sen2Res that is another plug in for the SNAP toolbox. Arguably SNAP is just a difference type of GIS software specific to Sentinel, but we will explore it later as it makes some of these concepts easier to understand.\nUpscaling aggregates the images to a more coarse resolution (e.g. 10m to 20m). The Sentinel user guide states that bands will be resampled and provided (e.g. within the 20m folder there are 10 bands). However, it’s not clear what method has been used, the documentation suggests nearest neighbour - https://docs.sentinel-hub.com/api/latest/data/sentinel-2-l2a/.\nThis can also be termed resampling, and nearest neighbour simply means taking the new raster resolution and then assiging the value from the closest value in the original data. Others approaches include bilinear or cubic convolution resampling.\n\n1.1.1.2 SNAP\nSNAP stands for Sentinels Application Platform it is a collection of toolboxes specifically for pre-processing and analysing remotely sensed data.\nSNAP allows us to easily do undertake many GIS raster type analysis that we’ve seen / discussed in other modules (like CASA0005) and that we will come across within this module including:\n\nre sampling raster data\nre projecting\nmasking\nclassifying data\nprincipal component analysis\northorectification\nmany more methods!\n\nAside from these methods in a GUI the real benefit is that it’s made to use remotely sensed data. Let’s explore some features of SNAP.\n\n1.1.1.2.1 Load data\n\nFile > Open Product > select the .zip that was downloaded. Do not rename it or unzip it before hand!\nIn the side bar under Product Explorer there will be a lot on data that you can load. The remotely sensed data in under Bands and then each band is listed (e.g. B1 443nm). What does 443nm mean?\nDouble right click on a layer and it will appear in the viewer area\n\n1.1.1.2.2 SNAP layout\nThe layout of SNAP isn’t too different to QGIS, we have:\n\nProducts on the left side bar\nMap info in the bottom left\n\nadditional panes of info can be added through view >toolbar windows\nnote i have added pixel info (updates when moving the cursor) and world map\n\n\nLayer / mask managers in the right sidebar\nProcessing tools in the top tool bars\n\n\n\n\n\n\n\n\n\nHere, i have also the two link buttons selected (bottom left window) these mean that if i move to another band i will still be in the same position on the image.\n\n1.1.1.2.3 Colour composites\nTo re-created a true colour composite, right click on the data product and open RGB image\n\n\n\n\n\n\n\n\nThere are a variety of other band combinations that we can use to show certain aspects of Earth’s surface based on the absorption and reflection properties of the materials in the wavelengths of the bands we display “through the colour guns”, for example:\n\nThe false colour composite: B8, B4, B3. Plants reflect near-infrared and green light whilst absorbing red….\nAtmospheric penetration composite: B12, B11, B8A with no visible bands to penetrate atmospheric particles. Vegetation = blue, urban area = white, gray cyan or purple.\nThe short-wave infrared composite: B12, B8A and B4 shows vegetation in green, the darker the greener the denser it is and brown shows built up or bare soil\n\nFor other band colour combinations consult gisgeogrpahy\n\n1.1.1.2.4 Creating a project\nBefore we go any further we should create a project, that way all our processed outputs will be stored within the projected and loaded again when we open it in future - like projects in any other software such as QGIS or R. Go File > Project > Save project. A project tab next to the product explorer tab will appear, but not you can’t access the bands from within the project that must be done through the product explorer.\n\n1.1.1.2.5 Image statistics\n\n1.1.1.2.6 Image histogram\nWhen we open an RGB image in SNAP the histogram is clipped by 1% at the lower end and 4% at the upper end and then mapped in bins between 0 and 255 for display. A computer screen in full RGB displays colours between 0 and 255, hence why this is done.\nThis is similar to the contrast enhancement we saw in QGIS and we can manually change it here again through View > Tool Windows > Colour Manipulation.\nChanging the distribution displayed will impact the colour of the image - try using the sliders or selecting 95% and 100% of all pixels to display. To reset click the back arrow button.\n\n\n\n\n\n\n\n\n\n1.1.1.2.6.1 Scatterplots\nUnder the analysis button there are a variety of tools we can use to explore some image statistics….for example, here i have created a scatter plot of band 4 (x axis) and band 8 ( y axis). These bands are the red (vegetation absorbs) and Near-infrared (NIR, that vegetation strongly reflects)…so where we have high values of NIR and low values of red the plot represents dense vegetation whilst low values of both red and NIR are usually wet bare soil:\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Remote Sensing 4113\n\n\n\n\nIn remote sensing this can be called “spectral feature space”, more on this later in the term. You might see the software ENVI in the source above - ENVI is propriety software that is similar to SNAP.\n\n1.1.1.2.6.2 Tasseled Caps\nThe output should look somewhat like a “Tasseled Cap” (a wizards hat at an angle), although this is different to the tasseled cap transformation which was proposed by Kauth and Thomas (1976). The tasseled cap transformation was originally applied to Landsat data being composed of brightness, greeness, yellow stuff (yes!) and none-such. It was then modified in 1968 to brightness, greeness and wetness. This can can useful for identifying urban areas, they are usually bright (although Andy will have more to say on this), high biomass will show in the greeness and moisture in the wetness. The tasseled cap comes from the plot between brightness on the x axis and greenness on the y axis.\nTraditionally this is usually only applied to Landsat data, however if our bands in other sensors (like Sentinel) cover the same wavelengths we can apply it…\n\\[Brightness = 0.3037(B2)+0.2793(B3)+\n0.4743(B4)+0.5585(B8)+\n0.5082(B11)+0.1863(B12)\\] \\[Greeness = −0.2848(B2)−0.2435(B3)\n−0.5436(B4)+0.7243(B8)+\n0.0840(B11)−0.1800(B12)\\] \\[Wetness = 0.1509(B2)+0.1973(B3)\n+0.3279(B4)+0.3406(B8)−\n0.7112(B11)−0.4572(B12)\\]\nNow, this is fairly straight forward to do in SNAP (or R) using Band Maths (Raster > Band Maths) and then clicking edit expression, before we can apply this we have two problems:\n\nB11 and B12 are at a 20 meter resolution where as all the others at a 10 meter resolution, to fix this we must re-sample to 20m\nUsing the image provided will mean that the entire tile is computed when we really only care about our study area\n\nNote, that there are many spatial indexes that can be applied to remotely sensed data, the Index DataBase holds them all or Chapter 8, pages 325 from Jensen is a good place to start.\n\n1.1.1.2.7 Masking and resampling\nThis is sometimes also called clipping in CASA0005 we saw cropping (to the extent of a polygon) and then masking. Here I am only interested in a study area of the City of Cape Town District Municipality, which is in the gadm40_ZAF_2 GADM data, it also appears in the gadm40_ZAF_3 data too!\nExplore the GADM data in QGIS to work out what spatial aggregation you can use to mask your study area. For the sake of this example you might want to use the smallest spatial unit, GADM level 4, which for South Africa is wards.\nSNAP only permits ESRI shapefile to be loaded! To do so you must select the product on interest in the product explorer > Vector > Import > ESRI Shapefile\nWhen you open a Shapefile in SNAP each polygon within your current extent will be made into an individual feature, opening the feature (from the Vector Data folder) will open the attribute table for the row of that polygon. You also might notice that the shapefile may have a larger extent than the image, this means we’d need to find another image and “mosaic” (merge or join together) them but we will see this later in the module, for now just accept that some area might be missing.\nIn my case the City of Capetown has been called ZAF_1 and now i will clip the raster to the polygon. However, the problem here is that we can only mask bands on the same spatial resolution, so we need to re sample bands 2,3,4 and 8 to 20m…here, we can use the Sentinel 2 resampling toolbox to resample the image and then move to masking it.\nThere are two options to resample within SNAP, a traditional resample which just considers the neighbouring pixels or the Sentinel 2 products resample to account for the particularities of the angle (satellite viewing) bands. For the sake of time we will use the traditional resample to generate a 20m raster dataset…Raster > Geometric > Resampling…\n\n\n\n\n\n\n\n\nNote that there will be both upsampling and downsampling here as i’ve selected a 20m output.\nThis will create a new product in the product explorer so make sure you use that from now we, next we can mask out the all the bands we need:\n\n\n\n\n\n\n\n\nTo mask out our study area use the Land/Sea mask (Raster > Masks > Land/Sea mask) and select the vector to use as the mask. Here, i only take forward the bands i need:\n\n\n\n\n\n\n\n\nAt this stage you may want to remove the shapefile that will still be within the new product created. Under the vector folder remove the relevant polygons.\nThen compute the tasseled cap transformation (Raster > Band Maths) with the equations above. Note that when using a subtraction (-) you might get invalid expression so use the inbuilt subtraction within the edit expression button.\nWe can now display the bands through the colour guns, R: Brightness, G: Greeness, B: Wetness and also create a scatter plot between Greeness (y) and Brightness (x) like we did earlier.\nAt this stage it is useful to also have open a true colour composite to compare to our tasseled cap transformation RBG image…what do the values and colours show? The [Tasseled Cap function](https://pro.arcgis.com/en/pro-app/2.7/help/analysis/raster-functions/tasseled-cap-function.htm#:~:text=The%20Tasseled%20Cap%20(Kauth%2DThomas,the%20graphical%20distribution%20of%20data.) from ArcPro will help explain this further.\n\n\n\n\n\n\n\n\n\n1.1.2 Landsat\nWe have seen in CASA0005 how to access Landsat imagery. Now go and source some cloud free Landsat 8 Collection 2 level 2 imagery (surface reflectance data) for your city…and unzip it.\nIn SNAP go File > Open Product, navigate to the .MTL and open it. The product should appear. This is a real benefit of SNAP, having data from multiple sensors in the same software that can e explored together - when you move around on the Landsat image then the Sentinel image will also move to the same location.\nTo see the bands (or RGB images) side by side use the window dividers in the top right …\n\n\n\n\n\n\n\n\nFor the next part of the practical we will compare the spectral signatures from both Sentinel and Landsat. To do so we need to generate a series of points of interest (called POIs) that are coincident in both images. First we need to do two things:\n\nClip all the spectral data from the Sentinel image to the vector outline\n\nwe will need to resample the Sentinel data to the same pixel size so consider what you want to do here\n\nupscale or downscale ?\nWhat bands over Sentinel and Landsat actually overlap, do you need all of them\n\nwhat resolution is useful\n\n\n\n\nClip the Landsat image to the same vector outline as the Sentinel image, during the mask you can select the bands to mask and output\n\n\n1.1.2.1 Select POIs\n\nTo create points of interest we want select pixels representative of certain land cover types (e.g. Bare earth, water, grass, forest, urban) so we can compare them from both Landsat and Sentinel. Of course the pixels need to be present in both datasets.\nWe can select pixels through QGIS, R or SNAP. I’ll focus on the latter here.\nMake a new vector data container for a land cover type (icon on the right in the image below). Note that it will be created within the data product that is selected.\n\n\n\n\n\n\n\n\n\n\nNext use a drawing tool to draw around areas of land cover, when you select the drawing tool you will be asked which landcover the polygon is for, make sure the area is in both imagery - switch between them as we have done or display them side by side. Whilst doing this it is useful to have the spectrum view open (View > Tool Windows > Optical >Spectrum Viewer:\n\n\n\n\n\n\n\n\n\n\nOnce done create another vector data container and repeat for the next land cover type.\nConsider have a separate class for highly reflective urban (e.g. industrial areas)\n\n1.1.3 Spectral signatures\nTo compare out spectral signatures we have a few options\n\nright click on the image in SNAP and then export mask pixels as a .txt, but you will need to do this for each land cover class and for each image (Sentinel and Landsat).\n\nor\n\nexport the imagery (to Geotiff) and vector files (to shapefiles) and then subset in R\n\nI will do the second option here:\n\nRight clicking on the vector containers will allow export to shapefile - do this for all the land covers you have\nTo export the “product” which is what your image will be un SNAP. Select it (just click it) then go File > Export > GeoTIFF. When exporting the Landsat data click the subset button in the save box > band subset (select only spectral bands) and then metadata subset and remove all the selection.\nOpen the GeoTIFFS and shapefiles in QGIS to check everything.This is another good opportunity to understand how contrast enhancement works - in QGIS > Symbology > expand min / max and then change the cumulative count cut the value for each band will change. For Landsat B3 is red, B2 is green and B1 is blue. This does not change the values of the pixels, just how they are displayed on a colour screen.\n\n1.1.4 Using R\nRemember that before we deal with large data sets in R, we must sort out the .gitignore file, if we intend to use Git and GitHub at any stage (hint: you will for the assessment). Go back to CASA0005 to remember how if you need to\nRaster packages in R have and are still evolving rapidly, we have probably seen and used the raster package and may have seen the terra or stars packages. All can handle raster data and do the same analysis (pretty much).\nIn 2023 some key packages will retire like maptools, rgdal and rgeos as their maintainer, Roger Bivand will retire. raster uses sp objects for vector data and also the rgdal package - the Geospatial Data Abstraction Library (GDAL) for reading, writing and converting between spatial formats. sp (that we saw in CASA0005) also uses rgdal and suggests rgeos.\nThe terra package (2020) is somewhat mixed with raster, however the retiring packages are only needed by raster, with the terra package replacing raster. Terra is much faster than raster as datasets that can’t be loaded into RAM are stored on disc and when loaded doesn’t read the values. Then when computations occur the do so in chunks. Terra is very well documented and the functions are very similar to raster - https://rspatial.org/terra/pkg/index.html\nThe stars package (2018) works with sf!!, this means many of the functions we’ve seen and are familiar with it will work - e.g. st_transform() which is much easier than doing it in raster. The real benefit of stars is its ability to handle large data (like satellite data) that can’t fit into memory. It does this through not loading the pixel values but keeping a reference to them through a proxy and only loading / running computations when specifically needed (e.g. plotting, will only plot the pixels that can be seen)! The stars section from Spatial Data Science in Pebesma and Bivnad 2022 gives a good overview with examples\nStars is faster than terra, terra is faster than raster.\n\n1.1.4.1 Data loading\n\nlibrary(sf)\n\nLinking to GEOS 3.9.1, GDAL 3.2.1, PROJ 7.2.1; sf_use_s2() is TRUE\n\nlibrary(stars)\n\nLoading required package: abind\n\nlibrary(terra)\n\nterra version 1.2.5\n\nlibrary(raster)\n\nLoading required package: sp\n\n\n\nbare_earth <- st_read(\"prac_1/Bare earth_Polygon.shp\")\ngrass <- st_read(\"prac_1/Grass_Polygon.shp\")\nforest <- st_read(\"prac_1/Forest_Polygon.shp\")\nurban <- st_read(\"prac_1/Urban_Polygon.shp\")\nhigh_urban <- st_read(\"prac_1/high_albedo_urban_Polygon.shp\")\n\n\n#Landsat equivalent\nbands <- c(\"2\", \"3\", \"4\", \"5\", \"6\", \"7\")\n\nsentinel <- rast(\"prac_1/S2A_MSIL2A_20220214T082031_N0400_R121_T34HBH_20220214T112437_spectral_compare.tif\")\n\nnames(sentinel) <- bands\n  \nlandsat<-rast(\"prac_1/subset_LC09_L2SP_175083_20220306_20220308_02_T1_msk2.tif\")\n\nnames(landsat) <- bands\n\nHere i have chosen to use terra, this is because i want to extract the pixel values from within the polygons and at the moment stars will only permit aggregation - e.g. the mean of the pixels in the polygons. This is fine unless you want to explore the variation in signatures! then you will need the values.\nTo use a vector layer in terra it needs to be in a SpatVector (in terra the raster is a SpatRaster). Now there are two ways we can do this…the first is with the vect() function from terra:\n\nurban <- vect(urban)\n\nIn the second we can actually convert the SpatRaster to a raster and then just use the sf object! I know, i know, how many formats do we need here! But this will mean we have a raster brick as we have all of our bands and a raster brick won’t work here.\n\nlandsat <- as(landsat, \"Raster\")\n\nOf course, we can just do this straight from loading the data with the pipe…\n\nbare_earth <- st_read(\"prac_1/Bare earth_Polygon.shp\") %>%\n  vect()\n\nReading layer `Bare earth_Polygon' from data source \n  `C:\\Users\\Andy\\OneDrive - University College London\\Teaching\\CASA0023\\CASA0023 practical book\\CASA0023 practical book\\prac_1\\Bare earth_Polygon.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 4 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 267432.5 ymin: 6257672 xmax: 288787.2 ymax: 6259819\nProjected CRS: WGS 84 / UTM zone 34S\n\ngrass <- st_read(\"prac_1/Grass_Polygon.shp\")%>%\n    vect()\n\nReading layer `Grass_Polygon' from data source \n  `C:\\Users\\Andy\\OneDrive - University College London\\Teaching\\CASA0023\\CASA0023 practical book\\CASA0023 practical book\\prac_1\\Grass_Polygon.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 4 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 278249.7 ymin: 6263712 xmax: 282905.1 ymax: 6269399\nProjected CRS: WGS 84 / UTM zone 34S\n\nforest <- st_read(\"prac_1/Forest_Polygon.shp\")%>%\n    vect()\n\nReading layer `Forest_Polygon' from data source \n  `C:\\Users\\Andy\\OneDrive - University College London\\Teaching\\CASA0023\\CASA0023 practical book\\CASA0023 practical book\\prac_1\\Forest_Polygon.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 4 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 276215.1 ymin: 6248998 xmax: 277411 ymax: 6251248\nProjected CRS: WGS 84 / UTM zone 34S\n\nurban <- st_read(\"prac_1/Urban_Polygon.shp\")%>%\n    vect()\n\nReading layer `Urban_Polygon' from data source \n  `C:\\Users\\Andy\\OneDrive - University College London\\Teaching\\CASA0023\\CASA0023 practical book\\CASA0023 practical book\\prac_1\\Urban_Polygon.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 4 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 272878.1 ymin: 6248261 xmax: 274459.4 ymax: 6249967\nProjected CRS: WGS 84 / UTM zone 34S\n\nhigh_urban <- st_read(\"prac_1/high_albedo_urban_Polygon.shp\")%>%\n    vect()\n\nReading layer `high_albedo_urban_Polygon' from data source \n  `C:\\Users\\Andy\\OneDrive - University College London\\Teaching\\CASA0023\\CASA0023 practical book\\CASA0023 practical book\\prac_1\\high_albedo_urban_Polygon.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 270154.1 ymin: 6246892 xmax: 285657.1 ymax: 6250286\nProjected CRS: WGS 84 / UTM zone 34S\n\n\nBefore we can start the extraction you might have seen that my Landsat data is not in the same CRS as the rest of the data, it’s close, but different. We can also just use the raster to get the CRS info, like\n\ncrs(landsat)\n\n[1] \"PROJCRS[\\\"WGS 84 / UTM zone 34N\\\",\\n    BASEGEOGCRS[\\\"WGS 84\\\",\\n        DATUM[\\\"World Geodetic System 1984\\\",\\n            ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n                LENGTHUNIT[\\\"metre\\\",1]]],\\n        PRIMEM[\\\"Greenwich\\\",0,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        ID[\\\"EPSG\\\",4326]],\\n    CONVERSION[\\\"UTM zone 34N\\\",\\n        METHOD[\\\"Transverse Mercator\\\",\\n            ID[\\\"EPSG\\\",9807]],\\n        PARAMETER[\\\"Latitude of natural origin\\\",0,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8801]],\\n        PARAMETER[\\\"Longitude of natural origin\\\",21,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8802]],\\n        PARAMETER[\\\"Scale factor at natural origin\\\",0.9996,\\n            SCALEUNIT[\\\"unity\\\",1],\\n            ID[\\\"EPSG\\\",8805]],\\n        PARAMETER[\\\"False easting\\\",500000,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8806]],\\n        PARAMETER[\\\"False northing\\\",0,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8807]]],\\n    CS[Cartesian,2],\\n        AXIS[\\\"(E)\\\",east,\\n            ORDER[1],\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        AXIS[\\\"(N)\\\",north,\\n            ORDER[2],\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n    USAGE[\\n        SCOPE[\\\"Engineering survey, topographic mapping.\\\"],\\n        AREA[\\\"Between 18Â°E and 24Â°E, northern hemisphere between equator and 84Â°N, onshore and offshore. Albania. Belarus. Bosnia and Herzegovina. Bulgaria. Central African Republic. Chad. Croatia. Democratic Republic of the Congo (Zaire). Estonia. Finland. Greece. Hungary. Italy. Kosovo. Latvia. Libya. Lithuania. Montenegro. North Macedonia. Norway, including Svalbard and Bjornoys. Poland. Romania. Russian Federation. Serbia. Slovakia. Sudan. Sweden. Ukraine.\\\"],\\n        BBOX[0,18,84,24]],\\n    ID[\\\"EPSG\\\",32634]]\"\n\ncrs(sentinel)\n\n[1] \"PROJCRS[\\\"WGS 84 / UTM zone 34S\\\",\\n    BASEGEOGCRS[\\\"WGS 84\\\",\\n        DATUM[\\\"World Geodetic System 1984\\\",\\n            ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n                LENGTHUNIT[\\\"metre\\\",1]]],\\n        PRIMEM[\\\"Greenwich\\\",0,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        ID[\\\"EPSG\\\",4326]],\\n    CONVERSION[\\\"UTM zone 34S\\\",\\n        METHOD[\\\"Transverse Mercator\\\",\\n            ID[\\\"EPSG\\\",9807]],\\n        PARAMETER[\\\"Latitude of natural origin\\\",0,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8801]],\\n        PARAMETER[\\\"Longitude of natural origin\\\",21,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8802]],\\n        PARAMETER[\\\"Scale factor at natural origin\\\",0.9996,\\n            SCALEUNIT[\\\"unity\\\",1],\\n            ID[\\\"EPSG\\\",8805]],\\n        PARAMETER[\\\"False easting\\\",500000,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8806]],\\n        PARAMETER[\\\"False northing\\\",10000000,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8807]]],\\n    CS[Cartesian,2],\\n        AXIS[\\\"(E)\\\",east,\\n            ORDER[1],\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        AXIS[\\\"(N)\\\",north,\\n            ORDER[2],\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n    USAGE[\\n        SCOPE[\\\"Engineering survey, topographic mapping.\\\"],\\n        AREA[\\\"Between 18Â°E and 24Â°E, southern hemisphere between 80Â°S and equator, onshore and offshore. Angola. Botswana. Democratic Republic of the Congo (Zaire). Namibia. South Africa. Zambia.\\\"],\\n        BBOX[-80,18,0,24]],\\n    ID[\\\"EPSG\\\",32734]]\"\n\n# reproject landsat\nlandsat <- project(landsat, sentinel)\n\nNow let’s pull out those values, and get the mean and standard deviation, starting with urban from sentinel data…\n\nlibrary(tidyverse)\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.3.5     v purrr   0.3.4\nv tibble  3.1.0     v dplyr   1.0.5\nv tidyr   1.2.0     v stringr 1.4.0\nv readr   2.1.2     v forcats 0.5.1\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx tidyr::expand()   masks terra::expand()\nx tidyr::extract()  masks raster::extract(), terra::extract()\nx dplyr::filter()   masks stats::filter()\nx dplyr::lag()      masks stats::lag()\nx dplyr::near()     masks terra::near()\nx tidyr::pack()     masks terra::pack()\nx dplyr::select()   masks raster::select()\nx tidyr::separate() masks terra::separate()\n\nsen_urban<- terra::extract(sentinel, urban, progress = F)%>%\n  as_tibble()%>%\n  pivot_longer(cols = 2:7, \n               names_to=\"bands\", \n               values_to=\"band_values\")%>%\n  add_column(sensor=\"sentinel\")%>%\n  add_column(land=\"urban\")\n\nNow, because this process will be the same for the other landcover types we can make a function…this is the exact same code as above but i’ve replaced two arguments with sensor and lancover that i can now change for each version (e.g. bare earth in Landsat or forest in Sentinel)\n\nband_fun <- function(sensor, landcover) {\n  col_sensor <- deparse(substitute(sensor))\n  col_land <- deparse(substitute(landcover))\n\n  sen_urban<- terra::extract(sensor, landcover, progress = F)%>%\n    as_tibble()%>%\n    pivot_longer(cols = 2:7, \n               names_to=\"bands\", \n               values_to=\"band_values\")%>%\n    add_column(sensor=col_sensor)%>%\n    add_column(land=col_land)\n                 \n}\n\nLater on we will also create a density plot, so let’s write a function for all the values…it’s very similar…we will call this one when we need it later…\n\nband_fun_all_values <- function(sensor, landcover) {\n  col_sensor <- deparse(substitute(sensor))\n  col_land <- deparse(substitute(landcover))\n\n  sen_urban<- terra::extract(sensor, landcover, progress = F)%>%\n    as_tibble()%>%\n    pivot_longer(cols = 2:7, \n               names_to=\"bands\", \n               values_to=\"band_values\")\n                 \n}\n\nThen it’s simply…\n\nsen_bare <- band_fun(sentinel, bare_earth)\nsen_grass<- band_fun(sentinel, grass) \nsen_forest<- band_fun(sentinel, forest) \nsen_high_urban <- band_fun(sentinel, high_urban) \n\nlsat_urban<- band_fun(landsat, urban)\nlsat_bare<- band_fun(landsat, bare_earth)\nlsat_grass<- band_fun(landsat, grass)\nlsat_forest<- band_fun(landsat, forest)\nlsat_high_urban <- band_fun(sentinel, high_urban) \n\nThink about what this has given us?\nThe next stage is to put then into a tibble: ::: {.cell}\nsen_lsat <- bind_rows(sen_urban, sen_bare, sen_grass,\n                      sen_forest, sen_high_urban,\n                      lsat_urban, lsat_bare, lsat_grass,\n                      lsat_forest, lsat_high_urban)\n:::\nThe next stage is to get the mean (and standard deviation) values for each band per sensor and land cover type:\n\nmeans<- sen_lsat%>%\n  group_by(bands, sensor, land)%>%\n  summarise(Mean=mean(band_values), Std=sd(band_values))\n\n`summarise()` has grouped output by 'bands', 'sensor'. You can override using\nthe `.groups` argument.\n\n\nPlot some spectral profiles, first for Sentinel…\n\np1 <- means %>%\n  filter(sensor==\"sentinel\") %>%\n  ggplot(., aes(x = bands, y = Mean,\n                col=land))+\n  geom_point()+\n  geom_line(aes(group = land)) +\n  geom_errorbar(aes(ymin = (Mean-Std), ymax = (Mean+Std), width = 0.2))\n\np1\n\n\n\n\nWe can also look at a density plot….ideally each land cover has a clear and separate historgram…\n\np2 <- sen_lsat %>%\n  filter(sensor==\"sentinel\") %>%\nggplot(., aes(x=band_values, group=land, fill=land)) + \n  geom_density(alpha = 0.6)+\n#Add a mean vertical line\n  geom_vline(data = . %>% group_by(land) %>% summarise(group_mean = mean(band_values)),\n             aes(xintercept=group_mean, color = land), linetype=\"dashed\", size=1)\n\np2\n\n\n\n\nRemember this mean vertical line is for all values per land cover, it’s not band specific.\nWe can arrange our grids nicely with the cowplot package…\n\nlibrary(cowplot)\n\nplot_grid(p1, p2, labels = c('A', 'B'), label_size = 12, ncol=1)\n\n\n\n\n\n1.1.5 Review questions\nWrite around 2-3 paragraphs on the following and support your responses with plots and literature:\n\nBriefly explain the process of sourcing, loading and manipulating remotely sensed datasets\nConsider the assumption made in comparing the spectral reflectance from Sentinel and Landsat\nReflect on why differences in the reflectance might occur.\n\nhttps://github.com/robmarkcole/satellite-image-deep-learning#techniques\nhttps://urbanspatial.github.io/classifying_satellite_imagery_in_R/#Supervised_Classification\nhttps://opengislab.com/blog/2018/5/14/flood-mapping-with-sentinel-1-data-using-snap-and-qgis"
  }
]