[
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "\n1  Getting started with remote sensing\n",
    "section": "",
    "text": "To start with we are going to send some time exploring remotely sensed data ready for future analysis. We will first look at Landsat, as we have seen this before in CASA0005. We will then move to Sentinel data.\nYou need to select a city of you choice and then using the image and explanation below…\n\n\n\n\n\n\nGo to the Copernicus Open Access Hub: https://scihub.copernicus.eu/dhus/#/home.\n\nYou will need to make a free account\n\nDraw around the study area\nSelect image filter criteria\nSelect search icon\nDownload the S2MSI2A data\n\n\n\n\n\n\n\n\n\n\n\nWithin this image we have:\n\nAllows you to either move around the global or draw a study area\nAn example of a study area\nHow to sort the image results\nSentinel mission selection :\n\n\nSentinel product types refer to the amount of processing that has been undertaken on the multi-spectral imagery. S2MSI2A = Bottom of Atmosphere (BOA) or otherwise known as surface reflectance. Consult the product specification for more details.\n\nYou can also use the Sentinel 2 toolbox to replicate the coverstion from TOA to BOA - https://sentinels.copernicus.eu/ar/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm\n\nThe platform refers to either sentinel 2A or 2B. Theses are the same sensors but they operate at 180 degrees from each other reducing the revisit time from 10 to 5 days. 2A was launched first in 2015 followed by 2B in 2017.\nCloud cover e.g. [0 TO 5]\n\nOnce downloaded and unzipped you’ll be presented with a load of folders! Here we are interested in the 10m bands…which are:\n\n\n\n\n\n\n\n\nYou’ll find then in the GRANULE > sensor number > IMG_DATA > R10.\nNext open them up in QGIS to explore, if there is a TCI image this is a True Colour Image of B02 (Blue), B03 (Green), and B04 (Red) Bands - open this first, it’s just a single raster layer. See the Sentinel user guide definitions for any other acronyms you might need.\n\n\n\n\n\n\n\n\nUsing the Identify tool we can create a spectral signature by changing the view option to graph (look under the graph in the image above).\nHowever the TCI values are coded between 0 and 255 which will limit what we can do with it. As the the radiometric resolution of Sentinel-2 is 12-bit, meaning brightness levels from 0 - 4095 it’s not clear how this product has been made.\nSo we can make our own raster stack using the BOA bands, if you recall we did this in CASA0005 in R.\nBut in QGIS it’s easier to visualise the output\nFind the merge tool from the Raster miscellaneous tool box and select the following:\n\n\n\n\n\n\n\n\nNote:\n\nThe input layers are the 4 10m bands that I loaded into QGIS\nThe tick box selected meaning each raster file will be it’s own layer\nThe file being saved into a .tiff as opposed to memory\n\nOnce merged we can created a true colour composite using the BOA data…to do so:\n\nRight click on the merged layer in the attribute table\nSymbology > Render type > select multiband color\n\nIn remote sensing the Red, Green, Blue display options are often called colour guns that are used to display images on the screen. For a true colour composite B1=Blue, B2=Green, B3=Red.\nTry changing the contrast enhancement and see what happens, then consult GIS stack exchange to understand what is happening..\nOf course we have only used the 10m bands so far…there are two options that we can take to use the full range of spectral data:\n\nDownscale the other bands to 10m forming a super-resolution\nUpscale the 10m to 20m\n\nDown scaling is quite an intensive process and beyond the scope of this practical. However, it can be achieved using Sen2Res that is a plug in for the SNAP toolbox. Arguably SNAP is just another GIS specific to Sentinel, but we will explore it later as it makes some of these concepts easier to understand.\nUpscaling aggregates the images to a more coarse resolution (e.g. 10m to 20m). The Sentinel user guide states that bands will be resampled and provided (e.g. within the 20m folder there are 10 bands). However, it’s not clear what method has been used, the documentation suggests nearest neighbour - https://docs.sentinel-hub.com/api/latest/data/sentinel-2-l2a/.\nThis can also be termed resampling, and nearest neighbour simply means taking the new raster resolution and then assiging the value from the closest value in the original data. Others approaches include bilinear or cubic convolution resampling.\n\nSNAP stands for Sentinels Application Platform it is a collection of toolboxes specifically for pre-processing and analysing remotely sensed data.\nSNAP allows us to easily do undertake many GIS raster type analysis that we’ve seen / discussed in other modules (like CASA0005) and that we will come across within this module including:\n\nre sampling raster data\nre projecting\nmasking\nclassifying data\nprincipal component analysis\northorectification\nmany more methods!\n\nAside from these methods in a GUI the real benefit is that it’s made to use remotely sensed data, unlike QGIS or R that are more standard GIS software. Let’s explore some features of SNAP.\n\n\nFile > Open Product > select the .zip that was downloaded. Do not rename it or unzip it before hand!\nIn the side bar under Product Explorer there will be a lot on data that you can load. The remotely sensed data in under Bands and then each band is listed (e.g. B1 443nm). What does 443nm mean?\n\nThe layout of SNAP isn’t too different to QGIS, we have:\n\nProducts on the left side bar\nMap info in the bottom left\nLayer / mask managers in the right sidbar\nProcessing tools in the top tool bars\n\n\nUnder the analysis button there are a variety of tools we can use to explore some image statistics….for example, here i have created a scatter plot of band 4 (x axis) and band 8 ( y axis). These bands are the red (vegetation absorbs) and Near-infrared (NIR, that vegetation strongly reflects)…so where we have high values of NIR and low values of red the plot represents dense vegetation whilst low values of both red and NIR are usually wet bare soil:\nThe output should look somewhat like a “Tasseld Cap”, although this isn’t the tasseled cap transformation which we will have a quick look at..\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://geofaculty.uwyo.edu/rhowell/classes/remote_sensing/labs/lab_11_2018_alternate_vegetation.pdf\n\n\nEither way now we want to merge the 20m imagery\n\nhttps://github.com/robmarkcole/satellite-image-deep-learning#techniques\nhttps://urbanspatial.github.io/classifying_satellite_imagery_in_R/#Supervised_Classification\nhttps://opengislab.com/blog/2018/5/14/flood-mapping-with-sentinel-1-data-using-snap-and-qgis"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Remotely Sensing Cities and Environments",
    "section": "",
    "text": "Andy MacLachlan1\nLast updated: 2022-04-25"
  },
  {
    "objectID": "index.html#acknowledgement",
    "href": "index.html#acknowledgement",
    "title": "CASA0023 Remotely Sensing Cities and Environments",
    "section": "Acknowledgement",
    "text": "Acknowledgement\nThanks to the following academics who inspired the creating of the module and various concepts within it:\n\nDr Ellie Biggs\nDr Gareth Roberts\nDr Bryan Boruff\nProfessor Ted Milton\nDr Laurie Chisholm\n\nThanks again to the following people who have either contributed directly or provided code in repositories that have helped me style this book:\n\n\nR Studio\n\nSTAT 545\nrstudio4edu\nHadley Wickham\nAlison Presmanes Hill\nDesirée De Leon\nYihui Xie\nJulia Silge\nJenny Bryan\nOthers\n\nRobin Lovelace\nTwitter for R programmers\nMatt Ng\nStatQuest with Josh Starmer\nGarrick Aden‑Buie\n\n\n\nThe R package and analysis artwork used within this book has been produced by allison_horst, whilst artwork used in information boxes has been produced by Desirée De Leon. You can find Allison’s images on the stats illustration GitHub repository and Desirée’s on the rstudio4edu GitHub repository.\nI’ve certainly learnt a lot from their open code repositories!"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "CASA0023 Remotely Sensing Cities and Environments",
    "section": "Welcome",
    "text": "Welcome\nHello  and welcome to the Term 2 module Remotely Sensing Cities and Environments.\nSimilarly, to my Term 1 MSc module, CASA0005, this website holds all the practical instructions for the module. CASA0005 Geographic Information Systems and Science is a pre-requisite of the module so concepts taught there will mainly be assumed here."
  }
]